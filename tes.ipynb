{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "ds = pd.read_csv(\"data sinopsis.csv\")\n",
    "\n",
    "import re\n",
    "\n",
    "sentence = []\n",
    "\n",
    "for i in range (len(ds['Sinopsis'])) :\n",
    "    text = ds['Sinopsis'][i]\n",
    "    text = text.replace('\\n', '')\n",
    "    sentences = re.split('\\. |\\.',text)\n",
    "    sentence.append(sentences)\n",
    "\n",
    "ds['Sentence'] = sentence\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PREPROCESSING\n",
    "-Tokenizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\ASUS\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "\n",
    "tokenize = []\n",
    "\n",
    "for i in range (len(ds['Sentence'])) :\n",
    "    tokenizer = nltk.RegexpTokenizer(r\"\\w+\")\n",
    "    tokenized = [tokenizer.tokenize(s.lower()) for s in ds['Sentence'][i]]\n",
    "    tokenize.append(tokenized)\n",
    "ds['Tokenize'] = tokenize"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "STOPWORDS REMOVAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\ASUS\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'a',\n",
       " 'about',\n",
       " 'above',\n",
       " 'after',\n",
       " 'again',\n",
       " 'against',\n",
       " 'ain',\n",
       " 'all',\n",
       " 'am',\n",
       " 'an',\n",
       " 'and',\n",
       " 'any',\n",
       " 'are',\n",
       " 'aren',\n",
       " \"aren't\",\n",
       " 'as',\n",
       " 'at',\n",
       " 'be',\n",
       " 'because',\n",
       " 'been',\n",
       " 'before',\n",
       " 'being',\n",
       " 'below',\n",
       " 'between',\n",
       " 'both',\n",
       " 'but',\n",
       " 'by',\n",
       " 'can',\n",
       " 'couldn',\n",
       " \"couldn't\",\n",
       " 'd',\n",
       " 'did',\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'do',\n",
       " 'does',\n",
       " 'doesn',\n",
       " \"doesn't\",\n",
       " 'doing',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'down',\n",
       " 'during',\n",
       " 'each',\n",
       " 'few',\n",
       " 'for',\n",
       " 'from',\n",
       " 'further',\n",
       " 'had',\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'has',\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'have',\n",
       " 'haven',\n",
       " \"haven't\",\n",
       " 'having',\n",
       " 'he',\n",
       " 'her',\n",
       " 'here',\n",
       " 'hers',\n",
       " 'herself',\n",
       " 'him',\n",
       " 'himself',\n",
       " 'his',\n",
       " 'how',\n",
       " 'i',\n",
       " 'if',\n",
       " 'in',\n",
       " 'into',\n",
       " 'is',\n",
       " 'isn',\n",
       " \"isn't\",\n",
       " 'it',\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " 'just',\n",
       " 'll',\n",
       " 'm',\n",
       " 'ma',\n",
       " 'me',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'more',\n",
       " 'most',\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'my',\n",
       " 'myself',\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'now',\n",
       " 'o',\n",
       " 'of',\n",
       " 'off',\n",
       " 'on',\n",
       " 'once',\n",
       " 'only',\n",
       " 'or',\n",
       " 'other',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'out',\n",
       " 'over',\n",
       " 'own',\n",
       " 're',\n",
       " 's',\n",
       " 'same',\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'she',\n",
       " \"she's\",\n",
       " 'should',\n",
       " \"should've\",\n",
       " 'shouldn',\n",
       " \"shouldn't\",\n",
       " 'so',\n",
       " 'some',\n",
       " 'such',\n",
       " 't',\n",
       " 'than',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'the',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'them',\n",
       " 'themselves',\n",
       " 'then',\n",
       " 'there',\n",
       " 'these',\n",
       " 'they',\n",
       " 'this',\n",
       " 'those',\n",
       " 'through',\n",
       " 'to',\n",
       " 'too',\n",
       " 'under',\n",
       " 'until',\n",
       " 'up',\n",
       " 've',\n",
       " 'very',\n",
       " 'was',\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'we',\n",
       " 'were',\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " 'what',\n",
       " 'when',\n",
       " 'where',\n",
       " 'which',\n",
       " 'while',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'why',\n",
       " 'will',\n",
       " 'with',\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'wouldn',\n",
       " \"wouldn't\",\n",
       " 'y',\n",
       " 'you',\n",
       " \"you'd\",\n",
       " \"you'll\",\n",
       " \"you're\",\n",
       " \"you've\",\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves'}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "\n",
    "listStopword =  set(stopwords.words('english'))\n",
    "listStopword"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "important = []\n",
    "removed = []\n",
    "\n",
    "for i in range (len(ds['Tokenize'])) :\n",
    "  important_token = []\n",
    "  for sent in ds['Tokenize'][i] :\n",
    "    filtered = [s for s in sent if s not in listStopword]\n",
    "    important_token.append(filtered)\n",
    "  important.append(important_token)\n",
    "  sw_removed = [' '.join(t) for t in important_token]\n",
    "  removed.append(sw_removed)\n",
    "\n",
    "ds['Important'] = important\n",
    "ds['Removed'] = removed"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "STEMMING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "stemmed = []\n",
    "\n",
    "for i in range (len(ds['Removed'])) :\n",
    "    stemmer = PorterStemmer()\n",
    "    stemmed_sent = [stemmer.stem(sentence) for sentence in ds['Removed'][i]]\n",
    "    stemmed.append(stemmed_sent)\n",
    "ds['Stemmed'] = stemmed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "documents = []\n",
    "\n",
    "for i in range (len(ds['Stemmed'])) :\n",
    "    vec = TfidfVectorizer(lowercase=True)\n",
    "    document = vec.fit_transform(ds['Stemmed'][i])\n",
    "    documents.append(document)\n",
    "ds['Documents'] = documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11\n",
      "4\n",
      "11\n",
      "4\n",
      "17\n",
      "7\n",
      "17\n",
      "7\n",
      "20\n",
      "7\n",
      "17\n",
      "7\n",
      "14\n",
      "5\n",
      "21\n",
      "8\n",
      "20\n",
      "7\n",
      "20\n",
      "7\n",
      "27\n",
      "9\n",
      "28\n",
      "9\n",
      "28\n",
      "9\n",
      "22\n",
      "8\n",
      "23\n",
      "8\n",
      "25\n",
      "9\n",
      "19\n",
      "7\n",
      "28\n",
      "9\n",
      "21\n",
      "8\n",
      "14\n",
      "5\n",
      "24\n",
      "9\n",
      "19\n",
      "7\n",
      "25\n",
      "9\n",
      "25\n",
      "9\n",
      "18\n",
      "7\n",
      "21\n",
      "8\n",
      "21\n",
      "8\n",
      "20\n",
      "7\n",
      "15\n",
      "6\n",
      "15\n",
      "6\n",
      "21\n",
      "8\n",
      "26\n",
      "9\n",
      "20\n",
      "7\n",
      "9\n",
      "3\n",
      "24\n",
      "9\n",
      "23\n",
      "8\n",
      "15\n",
      "6\n",
      "19\n",
      "7\n",
      "20\n",
      "7\n",
      "20\n",
      "7\n",
      "26\n",
      "9\n",
      "18\n",
      "7\n",
      "13\n",
      "5\n",
      "19\n",
      "7\n",
      "29\n",
      "9\n",
      "23\n",
      "8\n",
      "28\n",
      "9\n",
      "18\n",
      "7\n",
      "25\n",
      "9\n",
      "31\n",
      "10\n",
      "25\n",
      "9\n",
      "18\n",
      "7\n",
      "22\n",
      "8\n",
      "17\n",
      "7\n",
      "43\n",
      "10\n",
      "22\n",
      "8\n",
      "21\n",
      "8\n",
      "17\n",
      "7\n",
      "17\n",
      "7\n",
      "19\n",
      "7\n",
      "25\n",
      "9\n",
      "21\n",
      "8\n",
      "29\n",
      "9\n",
      "21\n",
      "8\n",
      "19\n",
      "7\n",
      "19\n",
      "7\n",
      "22\n",
      "8\n",
      "49\n",
      "10\n",
      "15\n",
      "6\n",
      "29\n",
      "9\n",
      "21\n",
      "8\n",
      "28\n",
      "9\n",
      "32\n",
      "10\n",
      "21\n",
      "8\n",
      "14\n",
      "5\n",
      "17\n",
      "7\n",
      "27\n",
      "9\n",
      "26\n",
      "9\n",
      "14\n",
      "5\n",
      "24\n",
      "9\n",
      "13\n",
      "5\n",
      "17\n",
      "7\n",
      "16\n",
      "6\n",
      "25\n",
      "9\n",
      "21\n",
      "8\n",
      "21\n",
      "8\n",
      "23\n",
      "8\n",
      "17\n",
      "7\n",
      "18\n",
      "7\n",
      "21\n",
      "8\n",
      "12\n",
      "4\n",
      "31\n",
      "10\n",
      "22\n",
      "8\n",
      "15\n",
      "6\n",
      "28\n",
      "9\n",
      "11\n",
      "4\n",
      "10\n",
      "3\n",
      "18\n",
      "7\n",
      "15\n",
      "6\n",
      "22\n",
      "8\n",
      "26\n",
      "9\n",
      "17\n",
      "7\n",
      "20\n",
      "7\n",
      "14\n",
      "5\n",
      "19\n",
      "7\n",
      "20\n",
      "7\n",
      "17\n",
      "7\n",
      "20\n",
      "7\n",
      "30\n",
      "9\n",
      "16\n",
      "6\n",
      "13\n",
      "5\n",
      "25\n",
      "9\n",
      "16\n",
      "6\n",
      "17\n",
      "7\n",
      "16\n",
      "6\n",
      "19\n",
      "7\n",
      "24\n",
      "9\n",
      "12\n",
      "4\n",
      "16\n",
      "6\n",
      "16\n",
      "6\n",
      "10\n",
      "3\n",
      "20\n",
      "7\n",
      "7\n",
      "3\n",
      "18\n",
      "7\n",
      "18\n",
      "7\n",
      "17\n",
      "7\n",
      "19\n",
      "7\n",
      "10\n",
      "3\n",
      "16\n",
      "6\n",
      "22\n",
      "8\n",
      "12\n",
      "4\n",
      "15\n",
      "6\n",
      "16\n",
      "6\n",
      "16\n",
      "6\n",
      "16\n",
      "6\n",
      "12\n",
      "4\n",
      "11\n",
      "4\n",
      "29\n",
      "9\n",
      "12\n",
      "4\n",
      "14\n",
      "5\n",
      "7\n",
      "3\n",
      "28\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "n = 0\n",
    "hasil_ringkasan = []\n",
    "x = []\n",
    "\n",
    "for i in range (len(ds['Documents'])) :\n",
    "  \n",
    "  if len(ds['Sentence'][i]) <= 10 :\n",
    "    n = 3\n",
    "  elif len(ds['Sentence'][i]) >= 11 and len(ds['Sentence'][i]) <= 12 :\n",
    "    n = 4\n",
    "  elif len(ds['Sentence'][i]) >= 13 and len(ds['Sentence'][i]) <= 14 :\n",
    "    n = 5    \n",
    "  elif len(ds['Sentence'][i]) >= 15 and len(ds['Sentence'][i]) <= 16 :\n",
    "    n = 6\n",
    "  elif len(ds['Sentence'][i]) >= 17 and len(ds['Sentence'][i]) <= 20 :\n",
    "    n = 7\n",
    "  elif len(ds['Sentence'][i]) >= 21 and len(ds['Sentence'][i]) <= 23 :\n",
    "    n = 8\n",
    "  elif len(ds['Sentence'][i]) >= 24 and len(ds['Sentence'][i]) <= 30 :\n",
    "    n = 9\n",
    "  elif len(ds['Sentence'][i]) >= 31 :\n",
    "    n = 10\n",
    "\n",
    "  x.append(len(ds['Sentence'][i]))\n",
    "  print(len(ds['Sentence'][i]))\n",
    "  print(n)\n",
    "\n",
    "  document = ds['Documents'][i].toarray()\n",
    "  result = np.sum(document, axis=1)\n",
    "  result.shape\n",
    "\n",
    "  sorted(result)\n",
    "\n",
    "  top_n = np.argsort(result)[-n:]\n",
    "  # print(top_n)\n",
    "\n",
    "  summ_index = sorted(top_n)\n",
    "  # print(summ_index)\n",
    "\n",
    "  # print('Hasil Ringkasan: ')\n",
    "  arr = []\n",
    "  for j in summ_index:\n",
    "    arr.append(ds['Sentence'][i][j])\n",
    "  string = \". \".join(str(x) for x in arr)\n",
    "  hasil_ringkasan.append(string)\n",
    "ds['Hasil Ringkasan'] = hasil_ringkasan\n",
    "ds.to_csv('Hasil ringkasan rev.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'float' object has no attribute 'split'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32md:\\Skripsi Farhan\\Program skripsi\\tes.ipynb Cell 11\u001b[0m line \u001b[0;36m1\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Skripsi%20Farhan/Program%20skripsi/tes.ipynb#X13sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m     hypothesis \u001b[39m=\u001b[39m dt[\u001b[39m'\u001b[39m\u001b[39mHasil Ringkasan\u001b[39m\u001b[39m'\u001b[39m][i]\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Skripsi%20Farhan/Program%20skripsi/tes.ipynb#X13sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m     reference \u001b[39m=\u001b[39m dc[\u001b[39m'\u001b[39m\u001b[39mringkasan manusia\u001b[39m\u001b[39m'\u001b[39m][i]\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/Skripsi%20Farhan/Program%20skripsi/tes.ipynb#X13sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m     scores\u001b[39m.\u001b[39mappend(rouge\u001b[39m.\u001b[39;49mget_scores(hypothesis, reference))\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Skripsi%20Farhan/Program%20skripsi/tes.ipynb#X13sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m \u001b[39m# Hasil ROUGE-N akan menghasilkan nilai precision, recall, dan F1-score\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Skripsi%20Farhan/Program%20skripsi/tes.ipynb#X13sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m ds[\u001b[39m'\u001b[39m\u001b[39mscore rouge\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m scores\n",
      "File \u001b[1;32mc:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\rouge\\rouge.py:107\u001b[0m, in \u001b[0;36mRouge.get_scores\u001b[1;34m(self, hyps, refs, avg, ignore_empty)\u001b[0m\n\u001b[0;32m    104\u001b[0m \u001b[39massert\u001b[39;00m(\u001b[39mlen\u001b[39m(hyps) \u001b[39m==\u001b[39m \u001b[39mlen\u001b[39m(refs))\n\u001b[0;32m    106\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m avg:\n\u001b[1;32m--> 107\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_scores(hyps, refs)\n\u001b[0;32m    108\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_avg_scores(hyps, refs)\n",
      "File \u001b[1;32mc:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\rouge\\rouge.py:116\u001b[0m, in \u001b[0;36mRouge._get_scores\u001b[1;34m(self, hyps, refs)\u001b[0m\n\u001b[0;32m    113\u001b[0m sen_score \u001b[39m=\u001b[39m {}\n\u001b[0;32m    115\u001b[0m hyp \u001b[39m=\u001b[39m [\u001b[39m\"\u001b[39m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mjoin(_\u001b[39m.\u001b[39msplit()) \u001b[39mfor\u001b[39;00m _ \u001b[39min\u001b[39;00m hyp\u001b[39m.\u001b[39msplit(\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(_) \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m]\n\u001b[1;32m--> 116\u001b[0m ref \u001b[39m=\u001b[39m [\u001b[39m\"\u001b[39m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mjoin(_\u001b[39m.\u001b[39msplit()) \u001b[39mfor\u001b[39;00m _ \u001b[39min\u001b[39;00m ref\u001b[39m.\u001b[39;49msplit(\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(_) \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m]\n\u001b[0;32m    118\u001b[0m \u001b[39mfor\u001b[39;00m m \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmetrics:\n\u001b[0;32m    119\u001b[0m     fn \u001b[39m=\u001b[39m Rouge\u001b[39m.\u001b[39mAVAILABLE_METRICS[m]\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'float' object has no attribute 'split'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from rouge import Rouge\n",
    "\n",
    "dt = pd.read_csv(\"Hasil ringkasan rev.csv\")\n",
    "ds = pd.read_csv(\"data analisis hasil ringkasan.csv\", delimiter=\",\")\n",
    "dc = pd.read_csv(\"data sinopsis revisi.csv\", delimiter=\",\")\n",
    "\n",
    "\n",
    "# Inisialisasi objek ROUGE\n",
    "rouge = Rouge()\n",
    "\n",
    "scores = []\n",
    "# Menghitung ROUGE-N (unigram, bigram, trigram) \n",
    "for i in range (len(dt['Hasil Ringkasan'])) :\n",
    "    hypothesis = dt['Hasil Ringkasan'][i]\n",
    "    reference = dc['ringkasan manusia'][i]\n",
    "    scores.append(rouge.get_scores(hypothesis, reference))\n",
    "\n",
    "\n",
    "# Hasil ROUGE-N akan menghasilkan nilai precision, recall, dan F1-score\n",
    "ds['score rouge'] = scores\n",
    "\n",
    "scores = []\n",
    "# Menghitung ROUGE-N (unigram, bigram, trigram) \n",
    "for i in range (len(dt['Hasil Ringkasan'])) :\n",
    "    hypothesis = dt['Hasil Ringkasan'][i]\n",
    "    reference = ds['Hasil ringkasan Web'][i]\n",
    "    scores.append(rouge.get_scores(hypothesis, reference))\n",
    "\n",
    "\n",
    "# Hasil ROUGE-N akan menghasilkan nilai precision, recall, dan F1-score\n",
    "ds['score rouge web'] = scores\n",
    "ds.to_csv('hasil rouge rev.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RATA_RATA SCORE ROUGE\n",
      "rata-rata rouge-l f-1 score\n",
      "0.45371001094518965\n",
      "rata-rata rouge-1 f-1 score\n",
      "0.47566682472282795\n",
      "rata-rata rouge-2 f-1 score\n",
      "0.2654903947372555\n",
      "rata-rata precission\n",
      "0.37172843229074637\n",
      "rata-rata recall\n",
      "0.5920809218795011\n"
     ]
    }
   ],
   "source": [
    "n = 0\n",
    "p = 0\n",
    "r = 0\n",
    "rouge1 = 0\n",
    "rouge2 = 0\n",
    "\n",
    "for i in range (len(ds['score rouge'])) :\n",
    "    n += ds['score rouge'][i][0][\"rouge-l\"][\"f\"]\n",
    "mean = n/len(ds['score rouge rev'])\n",
    "\n",
    "for i in range (len(ds['score rouge'])) :\n",
    "    rouge1 += ds['score rouge'][i][0][\"rouge-1\"][\"f\"]\n",
    "mean1 = rouge1/len(ds['score rouge rev'])\n",
    "\n",
    "for i in range (len(ds['score rouge'])) :\n",
    "    rouge2 += ds['score rouge'][i][0][\"rouge-2\"][\"f\"]\n",
    "mean2 = rouge2/len(ds['score rouge'])\n",
    "\n",
    "for i in range (len(ds['score rouge'])) :\n",
    "    p += ds['score rouge'][i][0][\"rouge-l\"][\"p\"]\n",
    "meanp = p/len(ds['score rouge'])\n",
    "\n",
    "for i in range (len(ds['score rouge'])) :\n",
    "    r += ds['score rouge'][i][0][\"rouge-l\"][\"r\"]\n",
    "meanr = r/len(ds['score rouge'])\n",
    "\n",
    "print('RATA_RATA SCORE ROUGE')\n",
    "print('rata-rata rouge-l f-1 score')\n",
    "print(mean)\n",
    "print('rata-rata rouge-1 f-1 score')\n",
    "print(mean1)\n",
    "print('rata-rata rouge-2 f-1 score')\n",
    "print(mean2)\n",
    "print('rata-rata precission')\n",
    "print(meanp)\n",
    "print('rata-rata recall')\n",
    "print(meanr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RATA_RATA SCORE ROUGE WEB\n",
      "rata-rata rouge-l f-1 score\n",
      "0.4782165699501816\n",
      "rata-rata rouge-1 f-1 score\n",
      "0.4993927336140659\n",
      "rata-rata rouge-2 f-1 score\n",
      "0.27979356886398515\n",
      "rata-rata precission\n",
      "0.40648333689479865\n",
      "rata-rata recall\n",
      "0.588740909829239\n"
     ]
    }
   ],
   "source": [
    "n = 0\n",
    "p = 0\n",
    "r = 0\n",
    "rouge1 = 0\n",
    "rouge2 = 0\n",
    "\n",
    "for i in range (len(ds['score rouge web'])) :\n",
    "    n += ds['score rouge web'][i][0][\"rouge-l\"][\"f\"]\n",
    "mean = n/len(ds['score rouge web'])\n",
    "\n",
    "for i in range (len(ds['score rouge web'])) :\n",
    "    rouge1 += ds['score rouge web'][i][0][\"rouge-1\"][\"f\"]\n",
    "mean1 = rouge1/len(ds['score rouge web'])\n",
    "\n",
    "for i in range (len(ds['score rouge web'])) :\n",
    "    rouge2 += ds['score rouge web'][i][0][\"rouge-2\"][\"f\"]\n",
    "mean2 = rouge2/len(ds['score rouge web'])\n",
    "\n",
    "for i in range (len(ds['score rouge web'])) :\n",
    "    p += ds['score rouge web'][i][0][\"rouge-l\"][\"p\"]\n",
    "meanp = p/len(ds['score rouge web'])\n",
    "\n",
    "for i in range (len(ds['score rouge web'])) :\n",
    "    r += ds['score rouge web'][i][0][\"rouge-l\"][\"r\"]\n",
    "meanr = r/len(ds['score rouge web'])\n",
    "\n",
    "print('RATA_RATA SCORE ROUGE WEB')\n",
    "print('rata-rata rouge-l f-1 score')\n",
    "print(mean)\n",
    "print('rata-rata rouge-1 f-1 score')\n",
    "print(mean1)\n",
    "print('rata-rata rouge-2 f-1 score')\n",
    "print(mean2)\n",
    "print('rata-rata precission')\n",
    "print(meanp)\n",
    "print('rata-rata recall')\n",
    "print(meanr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nilai tertinggi : \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "24     0.746479\n",
       "124    0.608187\n",
       "131    0.602410\n",
       "Name: score rouge fmeasure, dtype: float64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_rouge = []\n",
    "for i in range (len(ds['score rouge'])) :\n",
    "    score_rouge.append(ds['score rouge'][i][0][\"rouge-l\"][\"f\"])\n",
    "ds['score rouge fmeasure'] = score_rouge\n",
    "print('nilai tertinggi : ')\n",
    "ds[\"score rouge fmeasure\"].nlargest(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nilai terendah : \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "55     0.284314\n",
       "43     0.302222\n",
       "140    0.302521\n",
       "Name: score rouge fmeasure, dtype: float64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('nilai terendah : ')\n",
    "ds[\"score rouge fmeasure\"].nsmallest(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nilai tertinggi : \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "126    0.719665\n",
       "122    0.635514\n",
       "17     0.628571\n",
       "Name: score rouge fmeasure web, dtype: float64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_rouge = []\n",
    "for i in range (len(ds['score rouge web'])) :\n",
    "    score_rouge.append(ds['score rouge web'][i][0][\"rouge-l\"][\"f\"])\n",
    "ds['score rouge fmeasure web'] = score_rouge\n",
    "print('nilai tertinggi : ')\n",
    "ds[\"score rouge fmeasure web\"].nlargest(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nilai terendah : \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "54    0.259740\n",
       "66    0.284314\n",
       "93    0.304348\n",
       "Name: score rouge fmeasure web, dtype: float64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('nilai terendah : ')\n",
    "ds[\"score rouge fmeasure web\"].nsmallest(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nilai tertinggi : \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "126    0.719665\n",
       "Name: score rouge fmeasure web, dtype: float64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_rouge = []\n",
    "for i in range (len(ds['score rouge web'])) :\n",
    "    score_rouge.append(ds['score rouge web'][i][0][\"rouge-l\"][\"f\"])\n",
    "ds['score rouge precisions web'] = score_rouge\n",
    "print('nilai tertinggi : ')\n",
    "ds[\"score rouge fmeasure web\"].nlargest(1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
